{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  val\r\n"
     ]
    }
   ],
   "source": [
    "! ls /scratch/cra354/ssl_data_96/supervised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/scratch/cra354/ssl_data_96/supervised\"\n",
    "# using smaller, dataset for dev\n",
    "#data_dir = \"/scratch/cra354/smaller_set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 299\n",
    "batch_size = 16\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "scale = 360\n",
    "use_parallel = True\n",
    "use_gpu = True\n",
    "epochs = 100\n",
    "\n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "        transforms.Resize(scale),\n",
    "        transforms.RandomResizedCrop(input_shape),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(degrees=90),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)]),\n",
    "        'val': transforms.Compose([\n",
    "        transforms.Resize(scale),\n",
    "        transforms.CenterCrop(input_shape),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)]),}\n",
    "\n",
    "\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                      data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.inception_v3(pretrained=False)\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 1000)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_conv = optim.SGD(list(filter(lambda p: p.requires_grad, \n",
    "                            model_conv.parameters())), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu=True, num_epochs=25, mixup = False, alpha = 0.1):\n",
    "    print(\"MIXUP\".format(mixup))\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                #augementation using mixup\n",
    "                if phase == 'train' and mixup:\n",
    "                    inputs = mixup_batch(inputs, alpha)\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                #if phase == 'val':\n",
    "                    #print(\"preds: {}\".format(preds))\n",
    "                    #print(\"labels: {}\".format(labels))\n",
    "                    #print(epoch_acc)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                #running_loss += loss.data[0]\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                if running_corrects > 1000:\n",
    "                    print('stats here:')\n",
    "                    epoch_acc = running_corrects.float() / torch.tensor(dataset_sizes[phase]).float().cuda()\n",
    "                    print(epoch_acc)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.float() / torch.tensor(dataset_sizes[phase]).float().cuda()\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def model_evaluation(mode, model_conv, input_data_loc, input_shape, use_gpu, name):\n",
    "    \"\"\"A function which evaluates the model and outputs the csv of predictions of validation and train.\n",
    "    mode:\n",
    "    model_conv:\n",
    "    input_data_loc:\n",
    "    input_shape:\n",
    "    use_gpu:\n",
    "    Output:\n",
    "    1) Prints score of train and validation (Write it to a log file)\n",
    "    \"\"\"\n",
    "    print(\"[Evaluating the data in {}]\".format(mode))\n",
    "    data_loc = os.path.join(input_data_loc, mode)\n",
    "\n",
    "    print(\"[Building dataloaders]\")\n",
    "    dataloaders, image_datasets = data_loader_predict(data_loc, input_shape, name)\n",
    "    class_to_idx = image_datasets.class_to_idx\n",
    "    imgs = [i[0] for i in image_datasets.imgs]\n",
    "    print(\"total number of {} images: {}\".format(mode, len(imgs)))\n",
    "    original, predicted, probs = [], [], []\n",
    "    for img, label in dataloaders:\n",
    "        if use_gpu:\n",
    "            inputs = Variable(img.cuda())\n",
    "        else:\n",
    "            inputs = Variable(img)\n",
    "        bs, ncrops, c, h, w = inputs.data.size()\n",
    "        output = model_conv(inputs.view(-1, c, h, w)) # fuse batch size and ncrops\n",
    "        if type(output) == tuple:\n",
    "            output, _ = output\n",
    "        else:\n",
    "            output = output\n",
    "        outputs = torch.stack([nn.Softmax(dim=0)(i) for i in output])\n",
    "        outputs = outputs.mean(0)\n",
    "        _, preds = torch.max(outputs, 0)\n",
    "        probs.append(outputs.data.cpu().numpy())\n",
    "        original.extend(label.numpy())\n",
    "        predicted.extend(preds.data.cpu().numpy())\n",
    "    print(\"Accuracy_score {} : {} \".format(mode,  accuracy_score(original, predicted)))\n",
    "    frame = pd.DataFrame(probs)\n",
    "    frame.columns = [\"class_{}\".format(i) for i in frame.columns]\n",
    "    frame[\"img_loc\"] = imgs\n",
    "    frame[\"original\"] = original\n",
    "    frame[\"predicted\"] = predicted\n",
    "    return frame, class_to_idx\n",
    "\n",
    "\n",
    "def model_evaluation_test(mode, model_conv, test_input_data_loc, input_shape, use_gpu, name):\n",
    "    dataloaders, image_datasets = data_loader_predict(test_input_data_loc, input_shape, name)\n",
    "    imgs =[i[0] for i in image_datasets.imgs]\n",
    "    print(\"total number of {} images: {}\".format(mode, len(imgs)))\n",
    "    predicted, probs = [], []\n",
    "    for img, label in dataloaders:\n",
    "        if use_gpu:\n",
    "            inputs = Variable(img.cuda())\n",
    "        else:\n",
    "            inputs = Variable(img)\n",
    "        bs, ncrops, c, h, w = inputs.data.size()\n",
    "        output = model_conv(inputs.view(-1, c, h, w)) # fuse batch size and ncrops\n",
    "        if type(output) == tuple:\n",
    "            output, _ = output\n",
    "        else:\n",
    "            output = output\n",
    "        outputs = torch.stack([nn.Softmax(dim=0)(i) for i in output])\n",
    "        outputs = outputs.mean(0)\n",
    "        _, preds = torch.max(outputs, 0)\n",
    "        probs.append(outputs.data.cpu().numpy())\n",
    "        predicted.extend(preds.data.cpu().numpy())\n",
    "    frame = pd.DataFrame(probs)\n",
    "    frame.columns = [\"class_{}\".format(i) for i in frame.columns]\n",
    "    frame[\"img_loc\"] = imgs\n",
    "    frame[\"predicted\"] = predicted\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = model_conv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIXUP\n",
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 441/4000 [05:13<42:13,  1.40it/s]"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_conv, dataloaders, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, use_gpu=True,\n",
    "                     num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
